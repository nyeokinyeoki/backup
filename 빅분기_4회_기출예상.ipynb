{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07ad681",
   "metadata": {},
   "source": [
    "출처입니다.  \n",
    "작업형 1 : https://www.kaggle.com/code/agileteam/4th-type1-python/notebook  \n",
    "작업형 2 : https://www.kaggle.com/code/agileteam/4th-t2-python/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f28275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34d72d",
   "metadata": {},
   "source": [
    "### 작업형 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2560556f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 컬럼의 1분위수 :  26.875\n",
      "age 컬럼의 3분위수 :  77.0\n",
      "두 값 차이의 절대값 = 50\n"
     ]
    }
   ],
   "source": [
    "# 1-1. age 컬럼의 3사분위수와 1사분위수의 차를 절대값으로 구하고, 소수점 버려서, 정수로 출력\n",
    "\n",
    "df = pd.read_csv(\"./data/csv/basic1.csv\")\n",
    "\n",
    "# df.info()\n",
    "# df.head()\n",
    "\n",
    "age_1q = df[\"age\"].quantile(0.25)\n",
    "age_3q = df[\"age\"].quantile(0.75)\n",
    "\n",
    "print(\"age 컬럼의 1분위수 : \",age_1q)\n",
    "print(\"age 컬럼의 3분위수 : \",age_3q)\n",
    "\n",
    "diff = abs(age_3q - age_1q)\n",
    "\n",
    "print(\"두 값 차이의 절대값 =\", int(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aff2fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수 = 90\n",
      "        id   type  reactions  comments  shares  likes  loves  wows  hahas  \\\n",
      "3116  3117  video        255       926     181    142    108     0      5   \n",
      "4624  4625  video       1397       771     695    765    485   139      4   \n",
      "4776  4777  video        259       695     263    151    106     0      2   \n",
      "4793  4794  video        146       303     221     73     69     2      1   \n",
      "4812  4813  video        184       530     224    101     80     0      1   \n",
      "\n",
      "      sads  angrys     ratio  \n",
      "3116     0       0  0.423529  \n",
      "4624     1       3  0.446671  \n",
      "4776     0       0  0.409266  \n",
      "4793     0       1  0.486301  \n",
      "4812     1       1  0.434783  \n"
     ]
    }
   ],
   "source": [
    "# 1-2.(loves반응+wows반응)/(reactions반응) 비율이 0.4보다 크고 0.5보다 작으면서, type 컬럼이 'video'인 데이터의 갯수\n",
    "\n",
    "df2 = pd.read_csv(\"./data/csv/fb.csv\")\n",
    "\n",
    "# df2.info()\n",
    "# df2.head()\n",
    "\n",
    "df2[\"ratio\"] = (df2[\"loves\"] + df2[\"wows\"]) / df2[\"reactions\"]\n",
    "\n",
    "df2_cnt = df2[(df2[\"ratio\"] > 0.4) & (df2[\"ratio\"] < 0.5) & (df2[\"type\"] == \"video\")]\n",
    "\n",
    "print(\"데이터 개수 =\", df2_cnt.shape[0])\n",
    "print(df2_cnt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ad2f695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "조건을 만족하는 데이터 갯수 = 6\n"
     ]
    }
   ],
   "source": [
    "# 1-3. date_added가 2018년 1월 이면서 country가 United Kingdom 단독 제작인 데이터의 갯수\n",
    "\n",
    "df3 = pd.read_csv(\"./data/csv/nf.csv\")\n",
    "\n",
    "# df3.info()\n",
    "# df3.head()\n",
    "\n",
    "# df3[\"country\"].value_counts()\n",
    "# df3[\"date_added\"].unique()\n",
    "\n",
    "df3_cond = df3[df3[\"date_added\"].str.contains(\"January.*2018\", na=False, regex=True) & (df3[\"country\"]==\"United Kingdom\")]\n",
    "# na=False는 null값을 False로 처리, regex=True는 정규 표현식으로 처리\n",
    "\n",
    "print(\"조건을 만족하는 데이터 갯수 =\",df3_cond.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8bf6ea",
   "metadata": {},
   "source": [
    "### 작업형 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e04085ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4665, 28) (2000, 28)\n",
      "f1 score : 0.3835\n",
      "교차 검증 best score : 0.5279742765273312\n",
      "교차 검증 best params : {'max_depth': 3, 'n_estimators': 100, 'num_leaves': 10}\n",
      "f1 score : 0.5441\n",
      "분류 예측 값 : [1 3 3 ... 1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# [마케팅] 자동차 시장 세분화\n",
    "# 자동차 회사는 새로운 전략을 수립하기 위해 4개의 시장으로 세분화했습니다.\n",
    "# 기존 고객 분류 자료를 바탕으로 신규 고객이 어떤 분류에 속할지 예측해주세요!\n",
    "\n",
    "# 예측할 값(y): \"Segmentation\" (1,2,3,4)\n",
    "# 평가: Macro f1-score\n",
    "# data: train.csv, test.csv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "rdst = 22\n",
    "\n",
    "car = pd.read_csv(\"./data/csv/train_4회유형.csv\")   # 학습용 데이터\n",
    "\n",
    "test = pd.read_csv(\"./data/csv/test_4회유형.csv\")   # 테스트용 데이터\n",
    "\n",
    "len_car = car.shape[0]\n",
    "\n",
    "\n",
    "car_conc = pd.concat([car.drop(\"Segmentation\", axis=1), test], axis=0)   # 학습용과 테스트 concat >> onehotencoding을 위해\n",
    "\n",
    "car_conc.drop(\"ID\", axis=1, inplace=True)   #ID 변수 제거\n",
    "\n",
    "\n",
    "car_oh = pd.get_dummies(car_conc)   # 범주형 변수 onehotencoding\n",
    "\n",
    "# train, test를 다시 분리\n",
    "\n",
    "car_oh_tr = car_oh.iloc[:len_car]\n",
    "car_oh_tt = car_oh.iloc[len_car:]\n",
    "\n",
    "X = car_oh_tr.copy()\n",
    "y = car[\"Segmentation\"]\n",
    "\n",
    "## train_test_split ##\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=rdst)\n",
    "\n",
    "## MinMaxScaling ##\n",
    "\n",
    "mmsc = MinMaxScaler()\n",
    "\n",
    "mmsc.fit(X_train)\n",
    "\n",
    "X_train_sc = mmsc.transform(X_train)\n",
    "X_test_sc = mmsc.transform(X_test)\n",
    "\n",
    "print(X_train_sc.shape, X_test_sc.shape)\n",
    "\n",
    "## lightgbm ## \n",
    "\n",
    "lg = LGBMClassifier(n_estimators=100)\n",
    "\n",
    "lg.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred = lg.predict(X_test)\n",
    "\n",
    "print(\"f1 score :\", round(f1_score(y_test, y_pred, average=\"macro\"),4))\n",
    "\n",
    "## 교차 검증 ##\n",
    "lg_g = LGBMClassifier()\n",
    "\n",
    "params = {\n",
    "    \"num_leaves\" : [10,20,30,50],\n",
    "    \"max_depth\" : [3,5,7],\n",
    "    \"n_estimators\" : [100, 200]\n",
    "}\n",
    "\n",
    "skfold = StratifiedKFold(shuffle=True,random_state=rdst)\n",
    "\n",
    "gridcv = GridSearchCV(lg_g, param_grid=params, cv=skfold)\n",
    "\n",
    "gridcv.fit(X_train_sc, y_train)\n",
    "\n",
    "print(\"교차 검증 best score :\", gridcv.best_score_)\n",
    "print(\"교차 검증 best params :\", gridcv.best_params_)\n",
    "\n",
    "y_pred_grid = gridcv.predict(X_test_sc)\n",
    "\n",
    "print(\"f1 score :\", round(f1_score(y_test, y_pred_grid, average=\"macro\"),4))\n",
    "\n",
    "\n",
    "# test_data 예측\n",
    "\n",
    "test_sc = mmsc.transform(car_oh_tt)\n",
    "\n",
    "predict_test = gridcv.predict(test_sc)\n",
    "\n",
    "print(\"분류 예측 값 :\", predict_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
